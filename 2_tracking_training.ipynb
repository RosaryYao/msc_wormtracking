{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2849bdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import deepcell\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import deepcell\n",
    "from deepcell.utils.tracking_utils import load_trks, trks_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "862d9f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell.utils.data_utils import get_data\n",
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "def load_data(path, mode, test_size=0.1, seed=0):\n",
    "    \"\"\"Loads dataset.\n",
    "    Args:\n",
    "         test_size (float): fraction of data to reserve as test data\n",
    "        seed (int): the seed for randomly shuffling the dataset\n",
    "    Returns:\n",
    "           tuple: (x_train, y_train), (x_test, y_test).\n",
    "    \"\"\"\n",
    "\n",
    "    train_dict, test_dict = get_data(\n",
    "        path,\n",
    "        mode=mode,\n",
    "        test_size=test_size,\n",
    "        seed=seed)\n",
    "    x_train, y_train = train_dict['X'], train_dict['y']\n",
    "    x_test, y_test = test_dict['X'], test_dict['y']\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6115ba8",
   "metadata": {},
   "source": [
    "## Set up file path constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a03bb99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import errno\n",
    "\n",
    "ROOT_DIR = './track_train'  # TODO: Change this! Usually a mounted volume\n",
    "\n",
    "MODEL_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'models'))\n",
    "LOG_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'logs'))\n",
    "#DATA_DIR = os.path.expanduser(os.path.join('~', '.keras', 'datasets'))\n",
    "OUTPUT_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'nuc_tracking'))\n",
    "\n",
    "# create directories if they do not exist\n",
    "for d in (MODEL_DIR, LOG_DIR, OUTPUT_DIR):\n",
    "    try:\n",
    "        os.makedirs(d)\n",
    "    except OSError as exc:  # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79eb853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(X_train, y_train), (X_test, y_test) = load_data('../train.npz', mode='sample')\n",
    "#print('X.shape: {}\\ny.shape: {}'.format(X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322b4ab8",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "\n",
    "To facilitate training, we transform each movie's image and lineage data into a `Track` object.\n",
    "`Tracks` help to encapsulate all of the feature creation from the movie, including:\n",
    "\n",
    "* Appearances: `(num_frames, num_objects, 32, 32, 1)`\n",
    "* Morphologies: `(num_frames, num_objects, 32, 32, 3)`\n",
    "* Centroids: `(num_frames, num_objects, 2)`\n",
    "* Normalized Adjacency Matrix: `(num_frames, num_objects, num_objects, 3)`\n",
    "* Temporal Adjacency Matrix (comparing across frames): `(num_frames - 1, num_objects, num_objects, 3)`\n",
    "\n",
    "All `Track` objects are then concatenated with each other (using `concat_tracks`) resulting in a single array for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aa85039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use 22956814_seq.trks as a test first  ### Because it requires sequential labels as well\n",
    "\n",
    "trks_data = load_trks('../22956814/22956814_seq.trks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5503d929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77fb82c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/DeepCell_Tracking-0.4.5-py3.7.egg/deepcell_tracking/utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, tracked_data, appearance_dim, distance_threshold)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0;31m# Correct lineages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_correct_lineages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;31m# Remove bad batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/DeepCell_Tracking-0.4.5-py3.7.egg/deepcell_tracking/utils.py\u001b[0m in \u001b[0;36m_correct_lineages\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             y_relabel, new_lineage = relabel_sequential_lineage(\n\u001b[0;32m--> 673\u001b[0;31m                 self.y[batch], self.lineages[batch])\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mnew_lineages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_lineage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/DeepCell_Tracking-0.4.5-py3.7.egg/deepcell_tracking/utils.py\u001b[0m in \u001b[0;36mrelabel_sequential_lineage\u001b[0;34m(y, lineage)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;31m# Fix parent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlineage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcell_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m         \u001b[0mnew_parent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mparent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mnew_lineage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_cell_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parent'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_parent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from deepcell_tracking.utils import Track\n",
    "\n",
    "all_tracks = Track(tracked_data=trks_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d94a1b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_tracks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_tracks' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from deepcell_tracking.utils import concat_tracks\n",
    "\n",
    "track_info = concat_tracks([all_tracks])\n",
    "for k, v in track_info.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301da78c",
   "metadata": {},
   "source": [
    "## Set up training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb7bb039",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'track_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16926/1116398166.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# find maximum number of cells in any frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmax_cells\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrack_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'appearances'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mn_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# number of graph convolutions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'track_info' is not defined"
     ]
    }
   ],
   "source": [
    "seed = 1   # random seed for training/validation data split\n",
    "batch_size = 16\n",
    "track_length = 30  # only train on 8 frames at once  ## 8\n",
    "val_size = .20  # % of data saved as validation\n",
    "test_size = .1  # % of data held out as a test set\n",
    "n_epochs = 12  # number of training epochs\n",
    "\n",
    "steps_per_epoch = 100  ## 1000\n",
    "validation_steps = 20  ## 200\n",
    "\n",
    "# find maximum number of cells in any frame\n",
    "max_cells = track_info['appearances'].shape[2]\n",
    "\n",
    "n_layers = 1  # number of graph convolutions\n",
    "\n",
    "translation_range = X_train.shape[-2]\n",
    "\n",
    "model_name = 'graph_tracking_model_seed{}'.format(seed)\n",
    "model_path = os.path.join(MODEL_DIR, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591a81f6",
   "metadata": {},
   "source": [
    "## Create Tracking Dataset object\n",
    "\n",
    "We then assemble `Tracks` as specified into a Tracking `Dataset` that is used during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2e1880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell.data.tracking import prepare_dataset\n",
    "\n",
    "\n",
    "train_data, val_data, test_data = prepare_dataset(\n",
    "    track_info,\n",
    "    rotation_range=180,\n",
    "    translation_range=translation_range,\n",
    "    seed=seed,\n",
    "    val_size=val_size,\n",
    "    test_size=test_size,\n",
    "    batch_size=batch_size,\n",
    "    track_length=track_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42783d6",
   "metadata": {},
   "source": [
    "## Instantiate and Compile the Model\n",
    "The goal is to predict the adjacency matrix and daughter adjacency matrix by attending over the edges provided by the spatiotemporal adjacency matrix (SAM). The SAM is constructed by linking cells that are in temporal or spatial proximity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2617ba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell.model_zoo.tracking import GNNTrackingModel\n",
    "\n",
    "tm = GNNTrackingModel(max_cells=max_cells, n_layers=n_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53140cb",
   "metadata": {},
   "source": [
    "Before a model can be trained, it must be compiled with the chosen optimizer, loss function, and metrics.\n",
    "\n",
    "This model uses padded data which must be flattened and filtered out before calling our metrics and loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dd39d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_flatten(y_true, y_pred):\n",
    "    n_classes = tf.shape(y_true)[-1]\n",
    "    new_shape = [-1, n_classes]\n",
    "    y_true = tf.reshape(y_true, new_shape)\n",
    "    y_pred = tf.reshape(y_pred, new_shape)\n",
    "\n",
    "    # Mask out the padded cells\n",
    "    good_loc = tf.where(y_true[:, 0] != -1)[:, 0]\n",
    "\n",
    "    y_true = tf.gather(y_true, good_loc, axis=0)\n",
    "    y_pred = tf.gather(y_pred, good_loc, axis=0)\n",
    "    return y_true, y_pred\n",
    "\n",
    "\n",
    "class Recall(tf.keras.metrics.Recall):\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true, y_pred = filter_and_flatten(y_true, y_pred)\n",
    "        super(Recall, self).update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "\n",
    "class Precision(tf.keras.metrics.Precision):\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true, y_pred = filter_and_flatten(y_true, y_pred)\n",
    "        super(Precision, self).update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "\n",
    "def loss_function(y_true, y_pred):\n",
    "    y_true, y_pred = filter_and_flatten(y_true, y_pred)\n",
    "    return deepcell.losses.weighted_categorical_crossentropy(\n",
    "        y_true, y_pred,\n",
    "        n_classes=tf.shape(y_true)[-1],\n",
    "        axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c769983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.optimizers import RectifiedAdam as RAdam\n",
    "\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = RAdam(lr=1e-3, clipnorm=0.001)\n",
    "\n",
    "# Define the loss function\n",
    "losses = {'temporal_adj_matrices': loss_function}\n",
    "\n",
    "# Define metrics\n",
    "metrics = [\n",
    "    Recall(class_id=0, name='same_recall'),\n",
    "    Recall(class_id=1, name='different_recall'),\n",
    "    Recall(class_id=2, name='daughter_recall'),\n",
    "    Precision(class_id=0, name='same_precision'),\n",
    "    Precision(class_id=1, name='different_precision'),\n",
    "    Precision(class_id=2, name='daughter_precision'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eed2dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "tm.training_model.compile(optimizer=optimizer, loss=losses, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97729058",
   "metadata": {},
   "source": [
    "## Train Model and Verify Performance\n",
    "\n",
    "Call fit on the compiled model, along with a defined set of callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4785d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU count\n",
    "from deepcell import train_utils\n",
    "num_gpus = train_utils.count_gpus()\n",
    "print('Training on {} GPUs'.format(num_gpus))\n",
    "\n",
    "# Train the model\n",
    "train_callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        model_path, monitor='val_loss',\n",
    "        save_best_only=True, verbose=1,\n",
    "        save_weights_only=False),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5, verbose=1,\n",
    "        patience=3, min_lr=1e-7)\n",
    "]\n",
    "\n",
    "loss_history = tm.training_model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_data,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=n_epochs,\n",
    "    verbose=1,\n",
    "    callbacks=train_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1471b2b6",
   "metadata": {},
   "source": [
    "Visualize the performance of the model by comparing the predicted classes of i frames in j movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde57270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "it = val_data.as_numpy_iterator()\n",
    "x_temp, y_temp = it.next()\n",
    "\n",
    "temp_adj = y_temp['temporal_adj_matrices']\n",
    "\n",
    "output = tm.training_model.predict(x_temp)\n",
    "\n",
    "fig, axes = plt.subplots(8, 7, figsize=(80, 80))\n",
    "\n",
    "for j in range(4):\n",
    "    for i in range(7):\n",
    "        pred = output[j, i, ...]\n",
    "        truth = temp_adj[j, i, ...]\n",
    "\n",
    "        summed = np.sum(truth, axis=-1)\n",
    "        bad_loc = np.where(summed == -3)[1]\n",
    "        end = bad_loc[0] - 1\n",
    "        summed = np.sum(truth, axis=-1)\n",
    "\n",
    "        axes[2 * j, i].imshow(\n",
    "            np.argmax(pred[0:end, 0:end, :], axis=-1),\n",
    "            cmap='jet', vmin=0, vmax=2)\n",
    "        axes[2 * j + 1, i].imshow(\n",
    "            np.argmax(truth[0:end, 0:end, :]==1, axis=-1),\n",
    "            cmap='jet', vmin=0, vmax=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb4b39b",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51971815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models for prediction\n",
    "inf_path = os.path.join(MODEL_DIR, 'TrackingModelInf')\n",
    "ne_path = os.path.join(MODEL_DIR, 'TrackingModelNE')\n",
    "\n",
    "tm.inference_model.save(inf_path)\n",
    "tm.neighborhood_encoder.save(ne_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7c63b1",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This model is used within an assignment problem framework to track cells through time-lapse sequences and build cell lineages. To see how this works on example data, see below. \n",
    "\n",
    "To use existing models for tracking (and segmentation), refer to its counterpart in the `deepcell.application` [notebook series](https://github.com/vanvalenlab/deepcell-tf/blob/master/notebooks/applications/Nuclear-Application.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08b41ab",
   "metadata": {},
   "source": [
    "## Load the Model and Track One Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab71ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Models\n",
    "from deepcell.model_zoo.tracking import GNNTrackingModel\n",
    "tm = GNNTrackingModel()\n",
    "\n",
    "# Load models for prediction\n",
    "# (update `ne_path` and `inf_path` if different from above)\n",
    "tm.neighborhood_encoder = tf.keras.models.load_model(ne_path)\n",
    "tm.inference_model = tf.keras.models.load_model(inf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568ea3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alter below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3085e48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose and load a dataset to track using the trained model\n",
    "benchmark_filename = 'HEK293_benchmarks.trks'\n",
    "(X_train, y_train), (X_test, y_test) = deepcell.datasets.tracked.hek293_bench.load_tracked_data(benchmark_filename)\n",
    "print('HEK293 -\\nX.shape: {}\\ny.shape: {}'.format(X_train.shape, y_train.shape))\n",
    "\n",
    "path_bench_trks = os.path.join(DATA_DIR, benchmark_filename)\n",
    "test_data = load_trks(path_bench_trks)\n",
    "\n",
    "benchmark_index = 1  # this one has divisions\n",
    "\n",
    "raw_images = test_data['X'][benchmark_index]\n",
    "labeled_movie = test_data['y'][benchmark_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7439b5f",
   "metadata": {},
   "source": [
    "### Import the cell tracking algorithm and track the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c3ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell_tracking import CellTracker\n",
    "\n",
    "cell_tracker = CellTracker(\n",
    "    movie=raw_images,\n",
    "    annotation=labeled_movie,\n",
    "    track_length=track_length,\n",
    "    neighborhood_encoder=tm.neighborhood_encoder,\n",
    "    tracking_model=tm.inference_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168a0003",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cell_tracker.track_cells()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3120e5a",
   "metadata": {},
   "source": [
    "### Review the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84e5357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View tracked results of each batch as a video\n",
    "# NB: This does not render well on GitHub\n",
    "from IPython.display import HTML\n",
    "from deepcell.utils.plot_utils import get_js_video\n",
    "\n",
    "# Raw\n",
    "HTML(get_js_video(np.expand_dims(raw_images, axis=0),\n",
    "                  batch=0, cmap='gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2255a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracked\n",
    "\n",
    "# Scale the colors to match the max cell label\n",
    "HTML(get_js_video(np.expand_dims(cell_tracker.y_tracked, axis=0),\n",
    "                  batch=0, cmap='cubehelix', vmin=0,\n",
    "                  vmax=len(cell_tracker.tracks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bfc38d",
   "metadata": {},
   "source": [
    "# Save the Output\n",
    "\n",
    "If desired, save the results in our compressed format (.trk - with lineage information), as a movie (.gif - images only/no lineage information), or both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0799495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trk file\n",
    "res_file_path = os.path.join(OUTPUT_DIR, 'hek_test.trk')\n",
    "cell_tracker.dump(res_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230cbb59",
   "metadata": {},
   "source": [
    "Optionally, save the output as `.tif` files or `.gif` files for easy inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da034046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "vmax = len(cell_tracker.y_tracked)\n",
    "\n",
    "raw = []\n",
    "tracked = []\n",
    "\n",
    "for i in range(cell_tracker.X.shape[0]):\n",
    "    new_image = cell_tracker.X[i, ..., 0]\n",
    "    raw_path = os.path.join(OUTPUT_DIR, 'image_%d.tiff' % i)\n",
    "    imageio.imwrite(raw_path, new_image.astype('uint8'))\n",
    "    raw.append(new_image.astype('uint8'))\n",
    "\n",
    "    label_image = cell_tracker.y_tracked[i, ..., 0].astype('uint8')\n",
    "    label_path = os.path.join(OUTPUT_DIR, 'label_%d.tiff' % i)\n",
    "    plt.imsave(label_path, label_image,\n",
    "               cmap='cubehelix', vmin=0, vmax=vmax)\n",
    "    # imageio.imwrite(label_path, label_image,\n",
    "    #                 cmap='cubehelix', vmin=0, vmax=vmax)\n",
    "    tracked.append(label_image.astype('uint8'))\n",
    "\n",
    "# Make gifs\n",
    "imageio.mimsave(os.path.join(OUTPUT_DIR, 'raw.gif'), raw)\n",
    "imageio.mimsave(os.path.join(OUTPUT_DIR, 'tracked.gif'), tracked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2728d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmarked results not included here... See the original notebook"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m78",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m78"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
