{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "This notebook is part of the `deepcell-tf` documentation: https://deepcell.readthedocs.io/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a segmentation model\n",
    "\n",
    "`deepcell-tf` leverages [Jupyter Notebooks](https://jupyter.org) in order to train models. Example notebooks are available for most model architectures in the [notebooks folder](https://github.com/vanvalenlab/deepcell-tf/tree/master/notebooks). Most notebooks are structured similarly to this example and thus this notebook serves as a core reference for the deepcell approach to model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import deepcell\n",
    "from deepcell.utils.data_utils import get_data\n",
    "from tensorflow.keras.utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, mode, test_size=0.2, seed=0):\n",
    "    \"\"\"Loads dataset.\n",
    "    Args:\n",
    "         test_size (float): fraction of data to reserve as test data\n",
    "        seed (int): the seed for randomly shuffling the dataset\n",
    "    Returns:\n",
    "           tuple: (x_train, y_train), (x_test, y_test).\n",
    "    \"\"\"\n",
    "    basepath = os.path.expanduser(os.path.join('~', '.keras', 'datasets'))\n",
    "    prefix = path.split(os.path.sep)[:-1]\n",
    "    data_dir = os.path.join(basepath, *prefix) if prefix else basepath\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    elif not os.path.isdir(data_dir):\n",
    "        raise IOError('{} exists but is not a directory'.format(data_dir))\n",
    "\n",
    "    train_dict, test_dict = get_data(\n",
    "        path,\n",
    "        mode=mode,\n",
    "        test_size=test_size,\n",
    "        seed=seed)\n",
    "    x_train, y_train = train_dict['X'], train_dict['y']\n",
    "    x_test, y_test = test_dict['X'], test_dict['y']\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "### Download the data from `deepcell.datasets`\n",
    "\n",
    "`deepcell.datasets` provides access to a set of annotated live-cell imaging datasets which can be used for training cell segmentation and tracking models.\n",
    "All dataset objects share the `load_data()` method, which allows the user to specify the name of the file (`path`), the fraction of data reserved for testing (`test_size`) and a `seed` which is used to generate the random train-test split.\n",
    "Metadata associated with the dataset can be accessed through the `metadata` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data (saves to ~/.keras/datasets)\n",
    "#filename = 'HeLa_S3.npz'\n",
    "#test_size = 0.1 # % of data saved as test\n",
    "#seed = 0 # seed for random train-test split\n",
    "\n",
    "#(X_train, y_train), (X_test, y_test) = deepcell.datasets.hela_s3.load_data(\n",
    "#    filename, test_size=test_size, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = np.load('../train.npz')\n",
    "\n",
    "#file['X'].shape\n",
    "#X = np.vstack(file['X'])[0:-1:176]\n",
    "#y = np.vstack(file['y'])[0:-1:176]\n",
    "\n",
    "#print(X.shape)\n",
    "#print(y.shape)\n",
    "\n",
    "#np.savez(\"../seg_train.npz\", X=X, y=y)\n",
    "\n",
    "test_size = 0.1 # % of data saved as test\n",
    "seed = 0 # seed for random train-test split\n",
    "filename = '../seg_train.npz'\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_data(\n",
    "    filename, test_size=test_size, seed=seed, mode='sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PanopticNet` models require square inputs. Reshape the data to meet the model requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped feature data from (396, 530, 530, 1) to (9900, 128, 128, 1)\n",
      "Reshaped training data from (396, 530, 530, 1) to (9900, 128, 128, 1)\n",
      "Reshaped feature data from (44, 530, 530, 1) to (1100, 128, 128, 1)\n",
      "Reshaped training data from (44, 530, 530, 1) to (1100, 128, 128, 1)\n",
      "X.shape: (9900, 128, 128, 1)\n",
      "y.shape: (9900, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "from deepcell.utils.data_utils import reshape_matrix\n",
    "\n",
    "size = 128\n",
    "\n",
    "X_train, y_train = reshape_matrix(X_train, y_train, reshape_size=size)\n",
    "X_test, y_test = reshape_matrix(X_test, y_test, reshape_size=size)\n",
    "print('X.shape: {}\\ny.shape: {}'.format(X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up filepath constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change DATA_DIR if you are not using `deepcell.datasets`\n",
    "#DATA_DIR = os.path.expanduser(os.path.join('~'))\n",
    "\n",
    "# DATA_FILE should be a npz file, preferably from `make_training_data`\n",
    "#DATA_FILE = os.path.join(DATA_DIR, filename)\n",
    "\n",
    "DATA_FILE = '../seg_train.npz'\n",
    "\n",
    "# confirm the data file is available\n",
    "assert os.path.isfile(DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up other required filepaths\n",
    "\n",
    "# If the data file is in a subdirectory, mirror it in MODEL_DIR and LOG_DIR\n",
    "PREFIX = os.path.relpath(os.path.dirname(DATA_FILE), DATA_DIR)\n",
    "\n",
    "ROOT_DIR = '~/featureNets_seg'  # TODO: Change this! Usually a mounted volume\n",
    "MODEL_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'models', PREFIX))\n",
    "LOG_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'logs', PREFIX))\n",
    "\n",
    "# create directories if they do not exist\n",
    "for d in (MODEL_DIR, LOG_DIR):\n",
    "    try:\n",
    "        os.makedirs(d)\n",
    "    except OSError as exc:  # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the PanopticNet Model\n",
    "\n",
    "Here we instantiate a `PanopticNet` model from `deepcell.model_zoo` using 3 semantic heads:\n",
    "inner distance (1 class),\n",
    "outer distance (1 class),\n",
    "foreground/background distance (2 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 0s 0us/step\n",
      "94781440/94765736 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from deepcell.model_zoo.panopticnet import PanopticNet\n",
    "\n",
    "classes = {\n",
    "    'inner_distance': 1,  # inner distance\n",
    "    'outer_distance': 1,  # outer distance\n",
    "    'fgbg': 2,  # foreground/background separation\n",
    "}\n",
    "\n",
    "model = PanopticNet(\n",
    "    backbone='resnet50',\n",
    "    input_shape=X_train.shape[1:],\n",
    "    norm_method='std',\n",
    "    num_semantic_classes=classes,\n",
    "    location=True,  # should always be true\n",
    "    include_top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for training\n",
    "\n",
    "### Set up training parameters.\n",
    "\n",
    "There are a number of tunable hyper parameters necessary for training deep learning models:\n",
    "\n",
    "**model_name**: Incorporated into any files generated during the training process.\n",
    "\n",
    "**backbone**: The majority of DeepCell models support a variety backbone choices specified in the \"backbone\" parameter. Backbones are provided through [keras_applications](https://github.com/keras-team/keras-applications) and can be instantiated with weights that are pretrained on ImageNet.\n",
    "\n",
    "**n_epoch**: The number of complete passes through the training dataset.\n",
    "\n",
    "**lr**: The learning rate determines the speed at which the model learns. Specifically it controls the relative size of the updates to model values after each batch.\n",
    "\n",
    "**optimizer**: The TensorFlow module [tf.keras.optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) offers optimizers with a variety of algorithm implementations. DeepCell typically uses the Adam or the SGD optimizers.\n",
    "\n",
    "**lr_sched**: A learning rate scheduler allows the learning rate to adapt over the course of model training. Typically a larger learning rate is preferred during the start of the training process, while a small learning rate allows for fine-tuning during the end of training.\n",
    "\n",
    "**batch_size**: The batch size determines the number of samples that are processed before the model is updated. The value must be greater than one and less than or equal to the number of samples in the training dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "\n",
    "model_name = 'watershed_centroid_nuclear_general_std'\n",
    "\n",
    "n_epoch = 5  # Number of training epochs\n",
    "test_size = .20  # % of data saved as test\n",
    "norm_method = 'whole_image'  # data normalization\n",
    "\n",
    "lr = 1e-5\n",
    "optimizer = Adam(lr=lr, clipnorm=0.001)\n",
    "lr_sched = rate_scheduler(lr=lr, decay=0.99)\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "min_objects = 3  # throw out images with fewer than this many objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the DataGenerators\n",
    "\n",
    "The `SemanticDataGenerator` can output any number of transformations for each image. These transformations are passed to `generator.flow()` as a list of transform names.\n",
    "\n",
    "Here we use `\"inner-distance\"`, `\"outer-distance\"` and `\"fgbg\"` to correspond to the inner distance, outer distance, and foreground background semantic heads, respectively. Keyword arguments may also be passed to each transform as a `dict` of transform names to `kwargs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Removing 9900 of 9900 images with fewer than 3 objects.\n",
      "WARNING:tensorflow:Removing 1100 of 1100 images with fewer than 3 objects.\n"
     ]
    }
   ],
   "source": [
    "from deepcell import image_generators\n",
    "from deepcell.utils import train_utils\n",
    "\n",
    "transforms = list(classes.keys())\n",
    "transforms_kwargs = {'outer-distance': {'erosion_width': 0}}\n",
    "\n",
    "\n",
    "# use augmentation for training but not validation\n",
    "datagen = image_generators.SemanticDataGenerator(\n",
    "    rotation_range=180,\n",
    "    shear_range=0,\n",
    "    zoom_range=(0.75, 1.25),\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "datagen_val = image_generators.SemanticDataGenerator(\n",
    "    rotation_range=0,\n",
    "    shear_range=0,\n",
    "    zoom_range=0,\n",
    "    horizontal_flip=0,\n",
    "    vertical_flip=0)\n",
    "    \n",
    "train_data = datagen.flow(\n",
    "    {'X': X_train, 'y': y_train},\n",
    "    seed=seed,\n",
    "    transforms=transforms,\n",
    "    transforms_kwargs=transforms_kwargs,\n",
    "    min_objects=min_objects,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_data = datagen_val.flow(\n",
    "    {'X': X_test, 'y': y_test},\n",
    "    seed=seed,\n",
    "    transforms=transforms,\n",
    "    transforms_kwargs=transforms_kwargs,\n",
    "    min_objects=min_objects,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the data generator output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-4db0dce9588f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0minner_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mouter_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "inputs, outputs = train_data.next()\n",
    "\n",
    "img = inputs[0]\n",
    "inner_distance = outputs[0]\n",
    "outer_distance = outputs[1]\n",
    "fgbg = outputs[2]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(15, 15))\n",
    "\n",
    "axes[0].imshow(img[..., 0])\n",
    "axes[0].set_title('Source Image')\n",
    "\n",
    "axes[1].imshow(inner_distance[0, ..., 0])\n",
    "axes[1].set_title('Inner Distance')\n",
    "\n",
    "axes[2].imshow(outer_distance[0, ..., 0])\n",
    "axes[2].set_title('Outer Distance')\n",
    "\n",
    "axes[3].imshow(fgbg[0, ..., 0])\n",
    "axes[3].set_title('Foreground/Background')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loss function for each semantic head\n",
    "\n",
    "Each semantic head is trained with it's own loss function. Mean Square Error is used for regression-based heads, whereas `weighted_categorical_crossentropy` is used for classification heads.\n",
    "\n",
    "The losses are saved as a dictionary and passed to `model.compile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of losses for each semantic head\n",
    "from tensorflow.keras.losses import MSE\n",
    "from deepcell import losses\n",
    "\n",
    "\n",
    "def semantic_loss(n_classes):\n",
    "    def _semantic_loss(y_true, y_pred):\n",
    "        if n_classes > 1:\n",
    "            return 0.01 * losses.weighted_categorical_crossentropy(\n",
    "                y_true, y_pred, n_classes=n_classes)\n",
    "        return MSE(y_true, y_pred)\n",
    "    return _semantic_loss\n",
    "\n",
    "\n",
    "loss = {}\n",
    "\n",
    "# Give losses for all of the semantic heads\n",
    "for layer in model.layers:\n",
    "    if layer.name.startswith('semantic_'):\n",
    "        n_classes = layer.output_shape[-1]\n",
    "        loss[layer.name] = semantic_loss(n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Call `fit` on the compiled model, along with a default set of callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell.utils.train_utils import get_callbacks\n",
    "from deepcell.utils.train_utils import count_gpus\n",
    "\n",
    "\n",
    "model_path = os.path.join(MODEL_DIR, '{}.h5'.format(model_name))\n",
    "loss_path = os.path.join(MODEL_DIR, '{}.npz'.format(model_name))\n",
    "\n",
    "num_gpus = count_gpus()\n",
    "\n",
    "print('Training on', num_gpus, 'GPUs.')\n",
    "\n",
    "train_callbacks = get_callbacks(\n",
    "    model_path,\n",
    "    lr_sched=lr_sched,\n",
    "    tensorboard_log_dir=LOG_DIR,\n",
    "    save_weights_only=num_gpus >= 2,\n",
    "    monitor='val_loss',\n",
    "    verbose=1)\n",
    "\n",
    "loss_history = model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=train_data.y.shape[0] // batch_size,\n",
    "    epochs=n_epoch,\n",
    "    validation_data=val_data,\n",
    "    validation_steps=val_data.y.shape[0] // batch_size,\n",
    "    callbacks=train_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test data\n",
    "\n",
    "Use the trained model to predict on new data. First, create a new prediction model without the foreground background semantic head. While this head is very useful during training, the output is unused during prediction. By using `model.load_weights(path, by_name=True)`, the semantic head can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell.model_zoo.panopticnet import PanopticNet\n",
    "\n",
    "classes = {\n",
    "    'inner_distance': 1,\n",
    "    'outer_distance': 1,\n",
    "}\n",
    "\n",
    "prediction_model = PanopticNet(\n",
    "    backbone='resnet50',\n",
    "    input_shape=X_train.shape[1:],\n",
    "    norm_method='std',\n",
    "    num_semantic_heads=2,\n",
    "    num_semantic_classes=classes,\n",
    "    location=True,  # should always be true\n",
    "    include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on testing data\n",
    "from timeit import default_timer\n",
    "\n",
    "start = default_timer()\n",
    "test_images = prediction_model.predict(X_test)\n",
    "watershed_time = default_timer() - start\n",
    "\n",
    "print('Watershed segmentation of shape', test_images[0].shape, 'in', watershed_time, 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "from deepcell_toolbox.deep_watershed import deep_watershed\n",
    "\n",
    "index = np.random.choice(X_test.shape[0])\n",
    "print(index)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 20))\n",
    "\n",
    "masks = deep_watershed(\n",
    "    test_images,\n",
    "    min_distance=10,\n",
    "    detection_threshold=0.1,\n",
    "    distance_threshold=0.01,\n",
    "    exclude_border=False,\n",
    "    small_objects_threshold=0)\n",
    "\n",
    "# calculated in the postprocessing above, but useful for visualizing\n",
    "inner_distance = test_images[0]\n",
    "outer_distance = test_images[1]\n",
    "\n",
    "coords = peak_local_max(\n",
    "    inner_distance[index],\n",
    "    min_distance=10,\n",
    "    threshold_abs=0.1,\n",
    "    exclude_border=False)\n",
    "\n",
    "# raw image with centroid\n",
    "axes[0].imshow(X_test[index, ..., 0])\n",
    "axes[0].scatter(coords[..., 1], coords[..., 0],\n",
    "                color='r', marker='.', s=10)\n",
    "\n",
    "axes[1].imshow(inner_distance[index, ..., 0], cmap='jet')\n",
    "axes[2].imshow(outer_distance[index, ..., 0], cmap='jet')\n",
    "axes[3].imshow(masks[index, ...], cmap='jet')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate results\n",
    "\n",
    "The `deepcell.metrics` package is used to measure advanced metrics for instance segmentation predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell_toolbox.metrics import Metrics\n",
    "from skimage.morphology import watershed, remove_small_objects\n",
    "from skimage.segmentation import clear_border\n",
    "\n",
    "outputs = model.predict(X_test)\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for i in range(outputs[0].shape[0]):\n",
    "\n",
    "    mask = deep_watershed(\n",
    "        [t[[i]] for t in outputs],\n",
    "        min_distance=10,\n",
    "        detection_threshold=0.1,\n",
    "        distance_threshold=0.01,\n",
    "        exclude_border=False,\n",
    "        small_objects_threshold=0)\n",
    "\n",
    "    y_pred.append(mask[0])\n",
    "\n",
    "y_pred = np.stack(y_pred, axis=0)\n",
    "y_pred = np.expand_dims(y_pred, axis=-1)\n",
    "y_true = y_test.copy()\n",
    "\n",
    "print('DeepWatershed - Remove no pixels')\n",
    "m = Metrics('DeepWatershed - Remove no pixels', seg=False)\n",
    "m.calc_object_stats(y_true, y_pred)\n",
    "print('\\n')\n",
    "\n",
    "for i in range(y_pred.shape[0]):\n",
    "    y_pred[i] = remove_small_objects(y_pred[i].astype(int), min_size=100)\n",
    "    y_true[i] = remove_small_objects(y_true[i].astype(int), min_size=100)\n",
    "\n",
    "print('DeepWatershed - Remove objects < 100 pixels')\n",
    "m = Metrics('DeepWatershed - Remove 100 pixels', seg=False)\n",
    "m.calc_object_stats(y_true, y_pred)\n",
    "print('\\n')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "environment": {
   "name": "common-cu110.m76",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m76"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
